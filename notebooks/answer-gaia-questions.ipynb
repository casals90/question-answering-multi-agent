{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be78205-6c1c-4e4d-ac28-473534e2ccce",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "This notebook demonstrates how to interact with a **Question Answering Multi-Agent System (QAMAS)** built using the **Reflex framework**. Reflex provides an event-driven environment that supports the orchestration of modular, reactive agents to collaboratively answer complex user queries.\n",
    "\n",
    "This notebook is specifically tailored for completing the **GAIA Hands-on Challenge** from the [Hugging Face Agents Course – Unit 4](https://huggingface.co/learn/agents-course/unit4/hands-on). It automates the process of retrieving evaluation questions, generating answers using a Reflex-powered multi-agent architecture, and submitting the responses back to Hugging Face for scoring.\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Structure\n",
    "\n",
    "The notebook is organized into three key stages:\n",
    "\n",
    "1. **Extract Phase**  \n",
    "   Retrieves a set of GAIA questions using the Hugging Face API. These questions are part of the official evaluation and require high-quality, reliable responses.\n",
    "\n",
    "2. **GAIA Question Answering**  \n",
    "   Uses the Reflex multi-agent system to answer each question by dynamically routing it through the appropriate agent pipeline. This phase showcases the collaborative and reactive capabilities of the architecture.\n",
    "\n",
    "3. **Load Phase**  \n",
    "   Submits the generated answers to the Hugging Face evaluation endpoint and retrieves scores that reflect the system's performance.\n",
    "\n",
    "---\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "The QAMAS follows a modular, pipeline-based architecture where each agent has a specialized role and communicates asynchronously via the Reflex environment. The interaction is initiated by the **Router Agent**, which delegates the query to a suitable path based on the nature of the question. Each path ends with a **Verifier Agent** ensuring the accuracy and quality of the response before the final answer is returned.\n",
    "\n",
    "#### Agent Overview\n",
    "\n",
    "- **Router Agent**  \n",
    "  The Router analyzes each GAIA question and dynamically routes it to the correct downstream agent(s):\n",
    "  - **Factual or up-to-date queries** → Researcher\n",
    "  - **Logical/mathematical reasoning** → Reasoner\n",
    "  - **Structured/tabular data** → Data Analyst\n",
    "\n",
    "- **Data Analysis Agent**  \n",
    "  Specializes in interpreting structured data (e.g., CSVs, tables) and performing:\n",
    "  - Aggregations\n",
    "  - Pattern recognition\n",
    "  - Calculations and filtering\n",
    "  - Format-compliant reporting\n",
    "\n",
    "- **Researcher Agent**  \n",
    "  Gathers external or current information from reliable sources using:\n",
    "  - Search queries\n",
    "  - Clarifying sub-questions\n",
    "  - Web tools or APIs (if available)\n",
    "  - Source evaluation and synthesis\n",
    "\n",
    "- **Reasoner Agent**  \n",
    "  Handles logical and mathematical queries by:\n",
    "  - Applying formal reasoning techniques\n",
    "  - Executing step-by-step deduction or computation\n",
    "  - Validating solutions with alternative approaches when necessary\n",
    "\n",
    "- **Generator Agent (Initial & Final)**  \n",
    "  Responsible for transforming intermediate outputs into concise final answers. Ensures:\n",
    "  - Clean formatting\n",
    "  - Adherence to expected answer type (e.g., string, list, number)\n",
    "  - Incorporation of verification feedback\n",
    "\n",
    "- **Verifier Agent**  \n",
    "  Evaluates the quality of the generated answer:\n",
    "  - Confirms factual and logical accuracy\n",
    "  - Ensures strict format compliance\n",
    "  - Highlights inconsistencies or omissions\n",
    "\n",
    "  If issues are found, it routes feedback to the Generator for answer refinement. This feedback loop improves both precision and robustness, especially important for evaluation benchmarks like GAIA.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Pipeline Graph\n",
    "\n",
    "Depending on the nature of each GAIA question, the system dynamically selects one of the following processing routes:\n",
    "\n",
    "- **Structured Data Questions**  \n",
    "  `Router → Data Analyst → Generator → Verifier → Generator`\n",
    "\n",
    "- **Factual + Reasoning Questions (Multi-hop)**  \n",
    "  `Router → Researcher → Reasoner → Generator → Verifier → Generator`\n",
    "\n",
    "- **Logical/Mathematical Questions**  \n",
    "  `Router → Reasoner → Generator → Verifier → Generator`\n",
    "\n",
    "Each pipeline concludes with a **Verifier-Generator** cycle that improves answer fidelity and ensures conformity to GAIA’s evaluation format and quality expectations.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/multi_agents_graph.png\" alt=\"Multi-Agent Pipeline Graph\"/>\n",
    "  <center><em>Figure 1: Multi-Agent Pipeline Graph showing different processing routes</em></center>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "This notebook serves both as a demonstration of Reflex-based agent collaboration and as a working solution for the Hugging Face GAIA evaluation challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc536b-6693-49e3-adbd-bc3b9a4c497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740b533-818a-4074-ae57-fa2f8fa2c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import huggingface_hub\n",
    "import time\n",
    "\n",
    "from src.agent import question_answering\n",
    "from src.data import extract, load\n",
    "from src.tools.startup import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a755a-49af-4534-a187-67034046e331",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f1f64-d4f3-4d42-978e-2e6c00738e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"1\"}, \n",
    "    \"recursion_limit\": 30\n",
    "}\n",
    "\n",
    "questions_file_path = os.path.join(\n",
    "    settings[\"volumes\"][\"raw\"], \"gaia_questions.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b09f42-3ba3-40ba-8a65-b76fa5eddc41",
   "metadata": {},
   "source": [
    "## 1. Extract Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646b589-2b8f-459a-a86c-8058fed3979d",
   "metadata": {},
   "source": [
    "Logging to Hugginface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e06de6-a3a9-481c-a3e9-be7e96f15970",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_hub.login(os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3842e1f-39c3-4f39-92ad-8bd6ad600ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(questions_file_path):\n",
    "    questions = extract.get_questions(settings[\"volumes\"][\"interim\"])\n",
    "else:\n",
    "    questions = extract.read_json_file(questions_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621a934-65dc-49b2-93f1-8e6d4bcb539d",
   "metadata": {},
   "source": [
    "## 2. GAIA Questions Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118a65f-2f8e-4196-a80c-5be2e5ae9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i, question in enumerate(questions, start=1):\n",
    "    print(f\"Question {i}: {question['question']}\")\n",
    "    print(\"*\"*30)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Execute the agents with the GAIA question\n",
    "    qa_agent = question_answering.QuestionAnsweringAgent(graph_config)\n",
    "    try:\n",
    "        answer = qa_agent.answer_gaia_question(\n",
    "            question, stream_mode=\"values\", subgraphs=False, debug=False)\n",
    "    except Exception as _:\n",
    "        answer = \"\"\n",
    "\n",
    "    # Save answer\n",
    "    answers.append({\n",
    "      \"task_id\": question[\"task_id\"],\n",
    "      \"submitted_answer\": answer\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa169c-5c9e-407c-85b2-f1330e90665e",
   "metadata": {},
   "source": [
    "## 3. Load Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd73bcd9-d8ed-4002-8148-e765c06bdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(questions_file_path):\n",
    "    load.save_json_file(questions, questions_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ddb8ee-cf59-4b52-9807-a45eb6997e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = load.submit_answers(answers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73784dfd-bb1d-4a97-9cd3-46591a73a54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
