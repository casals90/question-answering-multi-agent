{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be78205-6c1c-4e4d-ac28-473534e2ccce",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "This notebook demonstrates how to interact with a **Question Answering Multi-Agent System (QAMAS)** built using the **Reflex framework**. Reflex provides an event-driven environment that supports the orchestration of modular, reactive agents to collaboratively answer complex user queries.\n",
    "\n",
    "This notebook is specifically tailored for completing the **GAIA Hands-on Challenge** from the [Hugging Face Agents Course – Unit 4](https://huggingface.co/learn/agents-course/unit4/hands-on). It automates the process of retrieving evaluation questions, generating answers using a Reflex-powered multi-agent architecture, and submitting the responses back to Hugging Face for scoring.\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Structure\n",
    "\n",
    "The notebook is organized into three key stages:\n",
    "\n",
    "1. **Extract Phase**  \n",
    "   Retrieves a set of GAIA questions using the Hugging Face API. These questions are part of the official evaluation and require high-quality, reliable responses.\n",
    "\n",
    "2. **GAIA Question Answering**  \n",
    "   Uses the Reflex multi-agent system to answer each question by dynamically routing it through the appropriate agent pipeline. This phase showcases the collaborative and reactive capabilities of the architecture.\n",
    "\n",
    "3. **Load Phase**  \n",
    "   Submits the generated answers to the Hugging Face evaluation endpoint and retrieves scores that reflect the system's performance.\n",
    "\n",
    "---\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "The QAMAS follows a modular, pipeline-based architecture where each agent has a specialized role and communicates asynchronously via the Reflex environment. The interaction is initiated by the **Router Agent**, which delegates the query to a suitable path based on the nature of the question. Each path ends with a **Verifier Agent** ensuring the accuracy and quality of the response before the final answer is returned.\n",
    "\n",
    "#### Agent Overview\n",
    "\n",
    "- **Router Agent**  \n",
    "  The Router analyzes each GAIA question and dynamically routes it to the correct downstream agent(s):\n",
    "  - **Factual or up-to-date queries** → Researcher\n",
    "  - **Logical/mathematical reasoning** → Reasoner\n",
    "  - **Structured/tabular data** → Data Analyst\n",
    "\n",
    "- **Data Analysis Agent**  \n",
    "  Specializes in interpreting structured data (e.g., CSVs, tables) and performing:\n",
    "  - Aggregations\n",
    "  - Pattern recognition\n",
    "  - Calculations and filtering\n",
    "  - Format-compliant reporting\n",
    "\n",
    "- **Researcher Agent**  \n",
    "  Gathers external or current information from reliable sources using:\n",
    "  - Search queries\n",
    "  - Clarifying sub-questions\n",
    "  - Web tools or APIs (if available)\n",
    "  - Source evaluation and synthesis\n",
    "\n",
    "- **Reasoner Agent**  \n",
    "  Handles logical and mathematical queries by:\n",
    "  - Applying formal reasoning techniques\n",
    "  - Executing step-by-step deduction or computation\n",
    "  - Validating solutions with alternative approaches when necessary\n",
    "\n",
    "- **Generator Agent (Initial & Final)**  \n",
    "  Responsible for transforming intermediate outputs into concise final answers. Ensures:\n",
    "  - Clean formatting\n",
    "  - Adherence to expected answer type (e.g., string, list, number)\n",
    "  - Incorporation of verification feedback\n",
    "\n",
    "- **Verifier Agent**  \n",
    "  Evaluates the quality of the generated answer:\n",
    "  - Confirms factual and logical accuracy\n",
    "  - Ensures strict format compliance\n",
    "  - Highlights inconsistencies or omissions\n",
    "\n",
    "  If issues are found, it routes feedback to the Generator for answer refinement. This feedback loop improves both precision and robustness, especially important for evaluation benchmarks like GAIA.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Pipeline Graph\n",
    "\n",
    "Depending on the nature of each GAIA question, the system dynamically selects one of the following processing routes:\n",
    "\n",
    "- **Structured Data Questions**  \n",
    "  `Router → Data Analyst → Generator → Verifier → Generator`\n",
    "\n",
    "- **Factual + Reasoning Questions (Multi-hop)**  \n",
    "  `Router → Researcher → Reasoner → Generator → Verifier → Generator`\n",
    "\n",
    "- **Logical/Mathematical Questions**  \n",
    "  `Router → Reasoner → Generator → Verifier → Generator`\n",
    "\n",
    "Each pipeline concludes with a **Verifier-Generator** cycle that improves answer fidelity and ensures conformity to GAIA’s evaluation format and quality expectations.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/multi_agents_graph.png\" alt=\"Multi-Agent Pipeline Graph\"/>\n",
    "  <center><em>Figure 1: Multi-Agent Pipeline Graph showing different processing routes</em></center>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "This notebook serves both as a demonstration of Reflex-based agent collaboration and as a working solution for the Hugging Face GAIA evaluation challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcc536b-6693-49e3-adbd-bc3b9a4c497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4740b533-818a-4074-ae57-fa2f8fa2c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 14:19:44 - Logger initialized\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import huggingface_hub\n",
    "\n",
    "from src.agent import question_answering\n",
    "from src.data import extract, load\n",
    "from src.tools.startup import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a755a-49af-4534-a187-67034046e331",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8f1f64-d4f3-4d42-978e-2e6c00738e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"1\"}, \n",
    "    \"recursion_limit\": 30\n",
    "}\n",
    "\n",
    "questions_file_path = os.path.join(settings[\"volumes\"][\"raw\"], \"gaia_questions.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b09f42-3ba3-40ba-8a65-b76fa5eddc41",
   "metadata": {},
   "source": [
    "## 1. Extract Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646b589-2b8f-459a-a86c-8058fed3979d",
   "metadata": {},
   "source": [
    "Logging to Hugginface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e06de6-a3a9-481c-a3e9-be7e96f15970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "huggingface_hub.login(os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3842e1f-39c3-4f39-92ad-8bd6ad600ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(questions_file_path):\n",
    "    questions = extract.get_questions(settings[\"volumes\"][\"interim\"])\n",
    "else:\n",
    "    questions = extract.read_json_file(questions_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661f5cdd-10b0-4ec5-9036-839a484d0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_list = extract.read_json_file(\"/data/processed/answers.json\")\n",
    "correct = extract.read_json_file(\"correct.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621a934-65dc-49b2-93f1-8e6d4bcb539d",
   "metadata": {},
   "source": [
    "## 2. GAIA Questions Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5118a65f-2f8e-4196-a80c-5be2e5ae9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2: In the video https://www.youtube.com/watch?v=L1vXCYZAYYM, what is the highest number of bird species to be on camera simultaneously?\n",
      "******************************\n",
      "a1e91b78-d3d8-4675-bb8d-62741b4b68a6\n",
      "Question 4: Review the chess position provided in the image. It is black's turn. Provide the correct next move for black which guarantees a win. Please provide your response in algebraic notation.\n",
      "cca530fc-4052-43b2-b130-b30968d8aa44\n",
      "******************************\n",
      "2025-05-20 14:19:44 - Adding png image to messages.\n",
      "2025-05-20 14:21:14 - Router:\n",
      "2025-05-20 14:21:14 - --------------------\n",
      "2025-05-20 14:21:14 - Route to reasoner agent with input 1... Bxh3\n",
      "\n",
      "\n",
      "2025-05-20 14:21:51 - Reasoner:\n",
      "2025-05-20 14:21:51 - --------------------\n",
      "2025-05-20 14:21:51 - Let’s number the key variations after 1...Bxh3! so you can see why it wins decisively.\n",
      "\n",
      "Position before Black’s move:\n",
      "  White: K on g1, Qh5, Re3, Bc3, Bd3, pawns on a3,f2,g2,h3  \n",
      "  Black: Kg8, Qb3, Rd8, Nd4, Be6, Bc8, pawns on a7,b7,c7,f7,g7,h6  \n",
      "\n",
      "1...Bxh3!  \n",
      "   Attacks the lone white rook on e3 (via the discovered attack of …Qd1+) and sets up a crushing pin/fork.\n",
      "\n",
      "a) 2.Rxh3?  \n",
      "   2...Qd1+!  \n",
      "   3.Qxd1 Bxh3  \n",
      "Black wins the rook on h3 and emerges a full piece ahead.\n",
      "\n",
      "b) 2.gxh3  \n",
      "   Again 2...Qd1+!  \n",
      "   3.Qxd1 Bxh3  \n",
      "Black comes out a piece ahead once more.\n",
      "\n",
      "No other defence improves White’s lot—Black wins material and the game.  \n",
      "\n",
      "Answer (in algebraic notation): 1...Bxh3!\n",
      "\n",
      "\n",
      "2025-05-20 14:21:54 - Generator:\n",
      "2025-05-20 14:21:54 - --------------------\n",
      "2025-05-20 14:21:54 - 1...Bxh3\n",
      "\n",
      "\n",
      "2025-05-20 14:21:57 - Verifier:\n",
      "2025-05-20 14:21:57 - --------------------\n",
      "2025-05-20 14:21:57 - The answer 1...Bxh3 is exactly the winning move in algebraic notation. It directly addresses the position, is factually correct, and matches the requested format—no changes needed.\n",
      "\n",
      "\n",
      "2025-05-20 14:22:02 - Generator:\n",
      "2025-05-20 14:22:02 - --------------------\n",
      "2025-05-20 14:22:02 - Bxh3\n",
      "\n",
      "\n",
      "Question 18: Who are the pitchers with the number before and after Taishō Tamai's number as of July 2023? Give them to me in the form Pitcher Before, Pitcher After, use their last names only, in Roman characters.\n",
      "******************************\n",
      "a0c07678-e491-4bbc-8f0b-07405144218f\n",
      "Question 19: The attached Excel file contains the sales of menu items for a local fast-food chain. What were the total sales that the chain made from food (not including drinks)? Express your answer in USD with two decimal places.\n",
      "******************************\n",
      "7bd855d8-463d-4ed5-93ca-5fe35145f733\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for i, question in enumerate(questions, start=1):\n",
    "    # print(f\"Question {i}: {question['question']}\")\n",
    "    # print(\"*\"*30)\n",
    "\n",
    "    if question[\"task_id\"] in correct[\"correct\"]:\n",
    "        # print(f\"Question {i}: {question['question']}\")\n",
    "        # print(\"*\"*30)\n",
    "        for an in answers_list:\n",
    "            if an[\"task_id\"] == question[\"task_id\"]:\n",
    "                answer = an[\"submitted_answer\"]\n",
    "                break\n",
    "    elif question[\"task_id\"] in (\"\"):\n",
    "        print(f\"Question {i}: {question['question']}\")\n",
    "        print(question[\"task_id\"])\n",
    "        print(\"*\"*30)\n",
    "        # Execute the agents with the GAIA question\n",
    "        qa_agent = question_answering.QuestionAnsweringAgent(graph_config)\n",
    "        try:\n",
    "            answer = qa_agent.answer_gaia_question(\n",
    "                question, stream_mode=\"values\", subgraphs=False, debug=False)\n",
    "        except Exception as _:\n",
    "            answer = \"\"\n",
    "    else:\n",
    "        print(f\"Question {i}: {question['question']}\")\n",
    "        print(\"*\"*30)\n",
    "        print(question[\"task_id\"])\n",
    "        answer = \"\"\n",
    "\n",
    "    # Save answer\n",
    "    answers.append({\n",
    "      \"task_id\": question[\"task_id\"],\n",
    "      \"submitted_answer\": answer\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88cab149-34d1-4c96-8dcc-76c5b00c2fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_id': '8e867cd7-cff9-4e6c-867a-ff5ddc2550be', 'submitted_answer': '3'},\n",
       " {'task_id': 'a1e91b78-d3d8-4675-bb8d-62741b4b68a6', 'submitted_answer': ''},\n",
       " {'task_id': '2d83110e-a098-4ebb-9987-066c06fa42d0',\n",
       "  'submitted_answer': 'right'},\n",
       " {'task_id': 'cca530fc-4052-43b2-b130-b30968d8aa44',\n",
       "  'submitted_answer': 'Bxh3'},\n",
       " {'task_id': '4fc2f1ae-8625-45b5-ab34-ad4433bc21f8',\n",
       "  'submitted_answer': 'FunkMonk'},\n",
       " {'task_id': '6f37996b-2ac7-44b0-8e68-6d28256631b4',\n",
       "  'submitted_answer': 'b, e'},\n",
       " {'task_id': '9d191bce-651d-4746-be2d-7ef8ecadb9c2',\n",
       "  'submitted_answer': 'Extremely'},\n",
       " {'task_id': 'cabe07ed-9eca-40ea-8ead-410ef5e83f91',\n",
       "  'submitted_answer': 'Louvrier'},\n",
       " {'task_id': '3cef3a44-215e-4aed-8e3b-b1e3f08063b7',\n",
       "  'submitted_answer': 'Broccoli, Celery, Fresh basil, Lettuce, Sweet potatoes'},\n",
       " {'task_id': '99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3',\n",
       "  'submitted_answer': 'cornstarch, freshly squeezed lemon juice, granulated sugar, pure vanilla extract, ripe strawberries'},\n",
       " {'task_id': '305ac316-eef6-4446-960a-92d80d542f82',\n",
       "  'submitted_answer': 'Wojciech'},\n",
       " {'task_id': 'f918266a-b3e0-4914-865d-4faa564f1aef', 'submitted_answer': '0'},\n",
       " {'task_id': '3f57289b-8c60-48be-bd80-01f8099ca449',\n",
       "  'submitted_answer': '519'},\n",
       " {'task_id': '1f975693-876d-457b-a649-393859e79bf3',\n",
       "  'submitted_answer': '132, 133, 134, 197, 245'},\n",
       " {'task_id': '840bfca7-4f7b-481a-8794-c560c340185d',\n",
       "  'submitted_answer': '80GSFC21M0002'},\n",
       " {'task_id': 'bda648d7-d618-4883-88f4-3466eabd860e',\n",
       "  'submitted_answer': 'Saint Petersburg'},\n",
       " {'task_id': 'cf106601-ab4f-4af9-b045-5295fe67b37d',\n",
       "  'submitted_answer': 'CUB'},\n",
       " {'task_id': 'a0c07678-e491-4bbc-8f0b-07405144218f', 'submitted_answer': ''},\n",
       " {'task_id': '7bd855d8-463d-4ed5-93ca-5fe35145f733', 'submitted_answer': ''},\n",
       " {'task_id': '5a0c1adf-205e-4841-a666-7c3ef95def9d',\n",
       "  'submitted_answer': 'Claus'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f19c79-5be6-4ba9-ad60-c57b836a0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbaa169c-5c9e-407c-85b2-f1330e90665e",
   "metadata": {},
   "source": [
    "## 3. Load Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd73bcd9-d8ed-4002-8148-e765c06bdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(questions_file_path):\n",
    "    load.save_json_file(questions, questions_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ddb8ee-cf59-4b52-9807-a45eb6997e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'casals90',\n",
       " 'score': 80.0,\n",
       " 'correct_count': 16,\n",
       " 'total_attempted': 20,\n",
       " 'message': 'Score calculated successfully: 16/20 total questions answered correctly (20 valid tasks attempted). Score did not improve previous record, leaderboard not updated.',\n",
       " 'timestamp': '2025-05-20T14:24:33.197010+00:00'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = load.submit_answers(answers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a06f7-4fa6-41d6-beee-daa4a6e217b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7ebd1-2870-4abd-8866-23ea390fd51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qu in questions:\n",
    "    if qu[\"task_id\"] not in correct[\"correct\"]:\n",
    "        print(qu)\n",
    "        print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb4d4b-f5ae-43f0-869f-d5c7c70492f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct[\"correct\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d5b01-3007-4f4b-a6a5-ef4772adcae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = [\n",
    "{'task_id': '7bd855d8-463d-4ed5-93ca-5fe35145f733',\n",
    "  'submitted_answer': 'USD89.706,00'}\n",
    "]\n",
    "\n",
    "response = load.submit_answers(an)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c9858-e5e7-4908-b070-7d9dcc2c4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for an in answers_list:\n",
    "    print(an)\n",
    "    response = load.submit_answers([an])\n",
    "    if response['correct_count'] == 1:\n",
    "        correct.append(an[\"task_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ca2fa-5331-4a16-a4e7-cf4aa490b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab14469-aa4d-4776-84a5-f19e921dee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be55f-84f0-4d96-ac02-b4c36428f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0ee32-d8d8-4ac7-8113-bc0f782a90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for an1 in answers_list:\n",
    "    for an2 in answers:\n",
    "        if an1[\"task_id\"] == an2[\"task_id\"]:\n",
    "            if an1[\"submitted_answer\"] != an2[\"submitted_answer\"]:\n",
    "                print(f\"An1 answer: {an1['submitted_answer']}\")\n",
    "                print(f\"An2 answer: {an2['submitted_answer']}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96785b99-ea3a-4f63-848b-cc1d793857a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55f79f-98a8-4271-b392-b06051bbbab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb112be6-22cf-4e21-ac71-d13181a81d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a57d29-13b0-4265-a2b5-91d36cb7b201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76a68f-d70a-4134-8c12-d3e0b1524003",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441febdd-8a18-44e9-b1d9-f1fd56038f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load.save_json_file(answers, \"answers_75.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18f509-0555-4100-b63c-caddb7bff699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load.save_json_file(correct, \"correct.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f865da-9427-4144-9dc1-56b19bdb33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcfdea-75f1-4333-add1-bd31ba294786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = '/data/interim/7bd855d8-463d-4ed5-93ca-5fe35145f733/7bd855d8-463d-4ed5-93ca-5fe35145f733.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df.head()\n",
    "\n",
    "selected_columns = [\n",
    "    \"Burgers\", \n",
    "    \"Hot Dogs\",\n",
    "    \"Salads\",\n",
    "    \"Fries\",\n",
    "    \"Ice Cream\"\n",
    "]\n",
    "df[selected_columns].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375df4e-e9c3-49d2-82a0-14c0ea51307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1479127-5cdd-42fe-9159-9883b8620069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cbcdb-5c5d-47aa-ab64-e0857b6240e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "from google.genai import types\n",
    "\n",
    "client\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='models/gemini-2.5-flash-preview-04-17',\n",
    "    contents=types.Content(\n",
    "        parts=[\n",
    "            types.Part(\n",
    "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=L1vXCYZAYYM')\n",
    "            ),\n",
    "            types.Part(text='what is the highest number of bird species to be on camera simultaneously?')\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea90d3-4988-4c4e-bbf3-ef4d62dd6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e54769-a754-47a4-9350-1ef7432105a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='models/gemini-2.5-flash-preview-04-17',\n",
    "    contents=types.Content(\n",
    "        parts=[\n",
    "            types.Part(\n",
    "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=1htKBjuUWec')\n",
    "            ),\n",
    "            types.Part(text='what does Teal\\'c say in response to the question \"Isn\\'t that hot?\"?')\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee4a31-b82c-45e2-9159-1d2284242a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4718da1-fb14-4fcc-9bd3-ed534f7a5997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73784dfd-bb1d-4a97-9cd3-46591a73a54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
