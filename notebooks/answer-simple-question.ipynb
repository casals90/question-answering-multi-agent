{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724ea620-052b-4ca8-af9b-ea6eb6c24632",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "This notebook demonstrates how to interact with a **Question Answering Multi-Agent System (QAMAS)** built using the **Reflex framework**. Reflex provides an event-driven environment that supports the orchestration of modular, reactive agents to collaboratively answer complex user queries.\n",
    "\n",
    "---\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "The QAMAS follows a modular, pipeline-based architecture where each agent has a specialized role and communicates asynchronously via the Reflex environment. The interaction is initiated by the **Router Agent**, which delegates the query to a suitable path based on the nature of the question. Each path ends with a **Verifier Agent** ensuring the accuracy and quality of the response before the final answer is returned.\n",
    "\n",
    "#### Agent Overview\n",
    "\n",
    "- **Router Agent**  \n",
    "  The Router is the entry point of the system. It analyzes the user's question and routes it to the appropriate processing pipeline based on its nature:\n",
    "  - **Factual or up-to-date queries** → Researcher\n",
    "  - **Logical/mathematical reasoning** → Reasoner\n",
    "  - **Structured/tabular data** → Data Analysis\n",
    "\n",
    "  It uses decision logic to assign one or more agents dynamically and provides a justification for its routing.\n",
    "\n",
    "- **Data Analysis Agent**  \n",
    "  Handles questions involving structured data such as tables or files (e.g., CSV, Excel). Responsibilities include:\n",
    "  - Parsing tabular formats\n",
    "  - Performing calculations or aggregations\n",
    "  - Identifying trends or extracting insights\n",
    "  - Formatting results as specified\n",
    "\n",
    "- **Researcher Agent**  \n",
    "  Gathers external or recent information from the web or specified knowledge sources. Tasks include:\n",
    "  - Constructing search queries\n",
    "  - Extracting relevant data\n",
    "  - Synthesizing and attributing findings\n",
    "  - Highlighting uncertainties or conflicts\n",
    "\n",
    "- **Reasoner Agent**  \n",
    "  Specialized in abstract, logical, or mathematical reasoning. Capabilities include:\n",
    "  - Deductive problem solving\n",
    "  - Multi-step computations\n",
    "  - Formal logic evaluations\n",
    "  - Providing verifiable, step-by-step solutions\n",
    "\n",
    "- **Generator Agent (Initial & Final)**  \n",
    "  Converts intermediate results into a clean, minimal answer tailored to the format expected by the user. It:\n",
    "  - Generates answers without excess explanation\n",
    "  - Uses history context to ensure correctness\n",
    "  - Reformulates answers after verification feedback\n",
    "\n",
    "- **Verifier Agent**  \n",
    "  Performs quality control by evaluating:\n",
    "  - Factual accuracy of the answer\n",
    "  - Logical consistency\n",
    "  - Output format compliance\n",
    "  - Omissions or over-explanations\n",
    "\n",
    "  If issues are found, feedback is returned to the Generator to produce an improved version. This validation step enhances **trustworthiness and precision** of responses.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Pipeline Graph\n",
    "\n",
    "The following are the system’s processing routes, depending on the question type:\n",
    "\n",
    "- **Tabular/Structured Data Queries**  \n",
    "  `Router → Data Analyst → Generator → Verifier → Generator`\n",
    "\n",
    "- **Factual + Reasoning Queries (multi-hop)**  \n",
    "  `Router → Researcher → Reasoner → Generator → Verifier → Generator`\n",
    "\n",
    "- **Logical/Mathematical Queries**  \n",
    "  `Router → Reasoner → Generator → Verifier → Generator`\n",
    "\n",
    "Each route concludes with a Verifier-Generator cycle to ensure the final answer meets quality and format expectations.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Questions\n",
    "\n",
    "These examples illustrate the diverse query types the system can handle:\n",
    "\n",
    "1. **Basic factual**  \n",
    "   *How many professional clubs has Lionel Messi played for?*\n",
    "\n",
    "2. **Entity extraction**  \n",
    "   *List the Nobel Prize winners in Physics between 2010 and 2020.*\n",
    "\n",
    "3. **Temporal reasoning**  \n",
    "   *What major geopolitical events occurred during the Cold War?*\n",
    "\n",
    "4. **Comparative analysis**  \n",
    "   *What are the differences between monolithic and microservices architectures?*\n",
    "\n",
    "5. **Causal inference**  \n",
    "   *What factors contributed to the 2008 financial crisis?*\n",
    "\n",
    "6. **Numerical insight**  \n",
    "   *What is the current inflation rate in the United States?*\n",
    "\n",
    "7. **Geospatial knowledge**  \n",
    "   *Which rivers flow through both Germany and Austria?*\n",
    "\n",
    "8. **Multi-hop reasoning**  \n",
    "   *Which U.S. presidents served in the military and later held office during wartime?*\n",
    "\n",
    "9. **Scientific explanation**  \n",
    "   *How does quantum entanglement differ from classical correlation?*\n",
    "\n",
    "10. **Ethical discussion**  \n",
    "   *What are the ethical challenges of using facial recognition technology in public spaces?*\n",
    "\n",
    "---\n",
    "\n",
    "By leveraging Reflex and a well-structured network of expert agents, this system is capable of handling a wide range of question types with both depth and precision. The modular design allows for scalability, while the Verifier component ensures a high standard of answer quality and consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcc536b-6693-49e3-adbd-bc3b9a4c497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4740b533-818a-4074-ae57-fa2f8fa2c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-15 09:32:28 - Logger initialized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.agent import question_answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a755a-49af-4534-a187-67034046e331",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8f1f64-d4f3-4d42-978e-2e6c00738e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"1\"}, \n",
    "    \"recursion_limit\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621a934-65dc-49b2-93f1-8e6d4bcb539d",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb0365-90aa-4c25-9cd0-ea0aa3368494",
   "metadata": {},
   "source": [
    "### Basic factual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6eb748-d28c-4f28-8af3-e96a9b8b2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_agent = question_answering.QuestionAnsweringAgent(graph_config)\n",
    "query = \"How many teams has Messi played for?\"\n",
    "answer = qa_agent.answer_question(\n",
    "    query, stream_mode=\"values\", subgraphs=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019af371-4325-4a27-a925-45e77b816663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac15b64-e797-40b7-a9e2-724bef216d08",
   "metadata": {},
   "source": [
    "### Entity extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce17fe3-3f9c-459b-ab3a-9358cb0a998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-15 09:32:33 - Router:\n",
      "2025-05-15 09:32:33 - --------------------\n",
      "2025-05-15 09:32:33 - Route to researcher agent with input List the Nobel Prize winners in Physics from 2010 to 2020.\n",
      "\n",
      "\n",
      "2025-05-15 09:32:57 - Researcher:\n",
      "2025-05-15 09:32:57 - --------------------\n",
      "2025-05-15 09:32:57 - Here are the Nobel Prize winners in Physics from 2010 to 2020, based on the information from the List of Nobel laureates in Physics Wikipedia article:\n",
      "\n",
      "*   **2010:** Andre Geim and Konstantin Novoselov \"for groundbreaking experiments regarding the two-dimensional material graphene\"\n",
      "*   **2011:** Saul Perlmutter, Brian P. Schmidt, and Adam G. Riess \"for the discovery of the accelerating expansion of the Universe through observations of distant supernovae\"\n",
      "*   **2012:** Serge Haroche and David J. Wineland \"for ground-breaking experimental methods that enable measuring and manipulation of individual quantum systems\"\n",
      "*   **2013:** François Englert and Peter Higgs \"for the theoretical discovery of a mechanism that contributes to our understanding of the origin of mass of subatomic particles, and which recently was confirmed through the discovery of the predicted elementary particle, by the ATLAS and CMS experiments at CERN's Large Hadron Collider\"\n",
      "*   **2014:** Isamu Akasaki, Hiroshi Amano, and Shuji Nakamura \"for the invention of efficient blue light-emitting diodes which has enabled bright and energy-saving white light sources\"\n",
      "*   **2015:** Takaaki Kajita and Arthur B. McDonald \"for the discovery of neutrino oscillations, which shows that neutrinos have mass\"\n",
      "*   **2016:** David J. Thouless, F. Duncan M. Haldane, and John M. Kosterlitz \"for theoretical discoveries of topological phase transitions and topological phases of matter\"\n",
      "*   **2017:** Rainer Weiss, Barry C. Barish, and Kip S. Thorne \"for the detection of gravitational waves\"\n",
      "*   **2018:** Arthur Ashkin, Gérard Mourou, and Donna Strickland \"for groundbreaking inventions in the field of laser physics\" (Arthur Ashkin \"for the optical tweezers and their application to biological systems\", Gérard Mourou and Donna Strickland \"for their method of generating high-intensity, ultrashort optical pulses\")\n",
      "*   **2019:** James Peebles, Michel Mayor, and Didier Queloz (James Peebles \"for theoretical discoveries in physical cosmology\", Michel Mayor and Didier Queloz \"for the discovery of an exoplanet orbiting a solar-type star\")\n",
      "*   **2020:** Roger Penrose, Reinhard Genzel, and Andrea Ghez (Roger Penrose \"for the discovery that black hole formation is a robust prediction of the general theory of relativity\", Reinhard Genzel and Andrea Ghez \"for the discovery of a supermassive compact object at the centre of our galaxy\")\n",
      "\n",
      "\n",
      "2025-05-15 09:32:59 - Reasoner:\n",
      "2025-05-15 09:32:59 - --------------------\n",
      "2025-05-15 09:32:59 - This list is correct and matches the information I provided regarding the Nobel Prize winners in Physics from 2010 to 2020, along with their citations.\n",
      "\n",
      "\n",
      "2025-05-15 09:33:02 - Generator:\n",
      "2025-05-15 09:33:02 - --------------------\n",
      "2025-05-15 09:33:02 - 2010: Andre Geim, Konstantin Novoselov\n",
      "2011: Saul Perlmutter, Brian P. Schmidt, Adam G. Riess\n",
      "2012: Serge Haroche, David J. Wineland\n",
      "2013: François Englert, Peter Higgs\n",
      "2014: Isamu Akasaki, Hiroshi Amano, Shuji Nakamura\n",
      "2015: Takaaki Kajita, Arthur B. McDonald\n",
      "2016: David J. Thouless, F. Duncan M. Haldane, John M. Kosterlitz\n",
      "2017: Rainer Weiss, Barry C. Barish, Kip S. Thorne\n",
      "2018: Arthur Ashkin, Gérard Mourou, Donna Strickland\n",
      "2019: James Peebles, Michel Mayor, Didier Queloz\n",
      "2020: Roger Penrose, Reinhard Genzel, Andrea Ghez\n",
      "\n",
      "\n",
      "2025-05-15 09:33:06 - Verifier:\n",
      "2025-05-15 09:33:06 - --------------------\n",
      "2025-05-15 09:33:06 - The proposed answer accurately lists the Nobel Prize winners in Physics for each year from 2010 to 2020, matching the information provided by the Reasoner agent. The format is a clear list, directly addressing the user's request without any unnecessary elaboration.\n",
      "\n",
      "**Verification Result:** Pass. The answer is correct, complete, and in an appropriate format.\n",
      "\n",
      "\n",
      "2025-05-15 09:33:08 - Generator:\n",
      "2025-05-15 09:33:08 - --------------------\n",
      "2025-05-15 09:33:08 - 2010: Andre Geim, Konstantin Novoselov\n",
      "2011: Saul Perlmutter, Brian P. Schmidt, Adam G. Riess\n",
      "2012: Serge Haroche, David J. Wineland\n",
      "2013: François Englert, Peter Higgs\n",
      "2014: Isamu Akasaki, Hiroshi Amano, Shuji Nakamura\n",
      "2015: Takaaki Kajita, Arthur B. McDonald\n",
      "2016: David J. Thouless, F. Duncan M. Haldane, John M. Kosterlitz\n",
      "2017: Rainer Weiss, Barry C. Barish, Kip S. Thorne\n",
      "2018: Arthur Ashkin, Gérard Mourou, Donna Strickland\n",
      "2019: James Peebles, Michel Mayor, Didier Queloz\n",
      "2020: Roger Penrose, Reinhard Genzel, Andrea Ghez\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa_agent = question_answering.QuestionAnsweringAgent(graph_config)\n",
    "query = \"List the Nobel Prize winners in Physics from 2010 to 2020.\"\n",
    "answer = qa_agent.answer_question(\n",
    "    query, stream_mode=\"values\", subgraphs=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97828d16-4484-4965-a695-1e6dc0c59917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: 2010: Andre Geim, Konstantin Novoselov\n",
      "2011: Saul Perlmutter, Brian P. Schmidt, Adam G. Riess\n",
      "2012: Serge Haroche, David J. Wineland\n",
      "2013: François Englert, Peter Higgs\n",
      "2014: Isamu Akasaki, Hiroshi Amano, Shuji Nakamura\n",
      "2015: Takaaki Kajita, Arthur B. McDonald\n",
      "2016: David J. Thouless, F. Duncan M. Haldane, John M. Kosterlitz\n",
      "2017: Rainer Weiss, Barry C. Barish, Kip S. Thorne\n",
      "2018: Arthur Ashkin, Gérard Mourou, Donna Strickland\n",
      "2019: James Peebles, Michel Mayor, Didier Queloz\n",
      "2020: Roger Penrose, Reinhard Genzel, Andrea Ghez\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a126d45-dc35-4bd6-9a9e-48d1dfe5f98d",
   "metadata": {},
   "source": [
    "### Causal reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0b7192-977e-4c2c-afee-89c51df00418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-15 09:34:41 - Router:\n",
      "2025-05-15 09:34:41 - --------------------\n",
      "2025-05-15 09:34:41 - Route to researcher agent with input What are the primary causes of deforestation in the Amazon rainforest?\n",
      "\n",
      "\n",
      "2025-05-15 09:34:50 - Researcher:\n",
      "2025-05-15 09:34:50 - --------------------\n",
      "2025-05-15 09:34:50 - The primary causes of deforestation in the Amazon rainforest are multifaceted, driven mainly by human activities. The most significant driver is **cattle ranching**, which accounts for a large majority of deforestation in the Brazilian Amazon as forests are cleared for pasture land.\n",
      "\n",
      "Other major causes include:\n",
      "*   **Agriculture:** This involves clearing land for crops, such as soybeans, and also includes small-scale farming.\n",
      "*   **Infrastructure development:** The construction of roads and dams opens up previously inaccessible areas to further exploitation.\n",
      "*   **Logging:** Both legal and illegal logging operations contribute to forest loss.\n",
      "*   **Mining:** Extraction of minerals also leads to deforestation, particularly illegal mining activities.\n",
      "\n",
      "These factors often interact, creating a complex web of causes behind the destruction of the Amazon rainforest.\n",
      "\n",
      "\n",
      "2025-05-15 09:34:54 - Reasoner:\n",
      "2025-05-15 09:34:54 - --------------------\n",
      "2025-05-15 09:34:54 - That is a correct and comprehensive summary of the primary causes of deforestation in the Amazon rainforest. The list accurately identifies the major drivers:\n",
      "\n",
      "1.  **Cattle Ranching:** Widely recognized as the single largest cause, particularly in the Brazilian Amazon.\n",
      "2.  **Agriculture:** Including large-scale soybean farming and smaller-scale subsistence farming.\n",
      "3.  **Infrastructure Development:** Roads and dams facilitating access and further exploitation.\n",
      "4.  **Logging:** Both legal and illegal operations.\n",
      "5.  **Mining:** Extraction activities, often illegal.\n",
      "\n",
      "These factors indeed interact and contribute to the complex process of forest loss in the region.\n",
      "\n",
      "\n",
      "2025-05-15 09:34:55 - Generator:\n",
      "2025-05-15 09:34:55 - --------------------\n",
      "2025-05-15 09:34:55 - Cattle ranching, agriculture, infrastructure development, logging, mining\n",
      "\n",
      "\n",
      "2025-05-15 09:34:58 - Verifier:\n",
      "2025-05-15 09:34:58 - --------------------\n",
      "2025-05-15 09:34:58 - The proposed answer accurately lists the primary causes of deforestation in the Amazon rainforest as identified in the history messages. It directly addresses the user's question and contains no unnecessary information. The format is a simple list, which is appropriate.\n",
      "\n",
      "**Verification Result:** Pass.\n",
      "\n",
      "\n",
      "2025-05-15 09:35:00 - Generator:\n",
      "2025-05-15 09:35:00 - --------------------\n",
      "2025-05-15 09:35:00 - Cattle ranching, agriculture, infrastructure development, logging, mining\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa_agent = question_answering.QuestionAnsweringAgent(graph_config)\n",
    "query = \"What are the primary causes of deforestation in the Amazon rainforest?\"\n",
    "answer = qa_agent.answer_question(\n",
    "    query, stream_mode=\"values\", subgraphs=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f0b292-cee2-484c-9406-e2e373c6792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: Cattle ranching, agriculture, infrastructure development, logging, mining\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a434d-f21c-416c-83aa-fecbf9f45a5b",
   "metadata": {},
   "source": [
    "### Geospatial understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e1e143-8972-4d9c-8a49-97a420109d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-15 09:41:13 - Router:\n",
      "2025-05-15 09:41:13 - --------------------\n",
      "2025-05-15 09:41:13 - Route to researcher agent with input Which countries share a border with Germany?\n",
      "\n",
      "\n",
      "2025-05-15 09:41:47 - Researcher:\n",
      "2025-05-15 09:41:47 - --------------------\n",
      "2025-05-15 09:41:47 - Germany shares a land border with nine neighboring countries.\n",
      "\n",
      "These countries are:\n",
      "*   Austria\n",
      "*   Belgium\n",
      "*   Czech Republic\n",
      "*   Denmark\n",
      "*   France\n",
      "*   Luxembourg\n",
      "*   Netherlands\n",
      "*   Poland\n",
      "*   Switzerland\n",
      "\n",
      "Germany has the second-highest number of bordering countries in Europe, after Russia. Its total land border length is approximately 3,713 kilometers (2,307 miles).\n",
      "\n",
      "An interesting geographical feature along the border is the Vennbahn railway line, which results in several small German exclaves surrounded by Belgian territory.\n",
      "\n",
      "Sources:\n",
      "*   Wikipedia (various articles on specific borders and lists of countries by borders)\n",
      "*   WorldAtlas, Barry's Borderpoints, Quora, Britannica (via Tavily search)\n",
      "\n",
      "\n",
      "2025-05-15 09:41:50 - Reasoner:\n",
      "2025-05-15 09:41:50 - --------------------\n",
      "2025-05-15 09:41:50 - Okay, I see. You are reiterating the list of nine countries that share a land border with Germany:\n",
      "\n",
      "*   Austria\n",
      "*   Belgium\n",
      "*   Czech Republic\n",
      "*   Denmark\n",
      "*   France\n",
      "*   Luxembourg\n",
      "*   Netherlands\n",
      "*   Poland\n",
      "*   Switzerland\n",
      "\n",
      "This information is consistent with the previous response. Thank you for providing it again.\n",
      "\n",
      "\n",
      "2025-05-15 09:41:51 - Generator:\n",
      "2025-05-15 09:41:51 - --------------------\n",
      "2025-05-15 09:41:51 - Austria, Belgium, Czech Republic, Denmark, France, Luxembourg, Netherlands, Poland, Switzerland\n",
      "\n",
      "\n",
      "2025-05-15 09:41:54 - Verifier:\n",
      "2025-05-15 09:41:54 - --------------------\n",
      "2025-05-15 09:41:54 - **Verification Result:** Pass\n",
      "\n",
      "**Feedback:** The proposed answer is accurate, complete, and directly addresses the user's question by listing the nine countries that share a border with Germany, as confirmed by the history. The format is appropriate, and there is no unnecessary content.\n",
      "\n",
      "\n",
      "2025-05-15 09:41:56 - Generator:\n",
      "2025-05-15 09:41:56 - --------------------\n",
      "2025-05-15 09:41:56 - Austria, Belgium, Czech Republic, Denmark, France, Luxembourg, Netherlands, Poland, Switzerland\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa_agent = question_answering.QuestionAnsweringAgent(graph_config)\n",
    "query = \"Which countries share a border with Germany?\"\n",
    "answer = qa_agent.answer_question(\n",
    "    query, stream_mode=\"values\", subgraphs=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fff1ee6-7c2d-4123-9d0f-5c779c86287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: Austria, Belgium, Czech Republic, Denmark, France, Luxembourg, Netherlands, Poland, Switzerland\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a2d0a-cc3f-4fe3-885a-a79972735dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
